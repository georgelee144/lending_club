{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is best thought of as a \"appendix\" to loan_ml. I am trying to investigate the usefulness of a logistic regression (logit) since it seems to have abysmal to no predictive value.\n",
    "\n",
    "Here I will try to find if I improve the logit function through a combination of preprocessing and hyper parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2506738 entries, 0 to 2506737\n",
      "Data columns (total 100 columns):\n",
      "loan_amnt                              float64\n",
      "term                                   int64\n",
      "int_rate                               float64\n",
      "installment                            float64\n",
      "grade                                  object\n",
      "sub_grade                              object\n",
      "emp_length                             int64\n",
      "home_ownership                         object\n",
      "annual_inc                             float64\n",
      "verification_status                    object\n",
      "loan_status                            int64\n",
      "purpose                                object\n",
      "dti                                    float64\n",
      "delinq_2yrs                            float64\n",
      "fico_range_low                         float64\n",
      "fico_range_high                        float64\n",
      "inq_last_6mths                         float64\n",
      "mths_since_last_delinq                 float64\n",
      "mths_since_last_record                 float64\n",
      "open_acc                               float64\n",
      "pub_rec                                float64\n",
      "revol_bal                              float64\n",
      "revol_util                             float64\n",
      "total_acc                              float64\n",
      "collections_12_mths_ex_med             float64\n",
      "mths_since_last_major_derog            float64\n",
      "application_type                       object\n",
      "annual_inc_joint                       float64\n",
      "dti_joint                              float64\n",
      "verification_status_joint              object\n",
      "acc_now_delinq                         float64\n",
      "tot_coll_amt                           float64\n",
      "tot_cur_bal                            float64\n",
      "open_acc_6m                            float64\n",
      "open_act_il                            float64\n",
      "open_il_12m                            float64\n",
      "open_il_24m                            float64\n",
      "mths_since_rcnt_il                     float64\n",
      "total_bal_il                           float64\n",
      "il_util                                float64\n",
      "open_rv_12m                            float64\n",
      "open_rv_24m                            float64\n",
      "max_bal_bc                             float64\n",
      "all_util                               float64\n",
      "total_rev_hi_lim                       float64\n",
      "inq_fi                                 float64\n",
      "total_cu_tl                            float64\n",
      "inq_last_12m                           float64\n",
      "acc_open_past_24mths                   float64\n",
      "avg_cur_bal                            float64\n",
      "bc_open_to_buy                         float64\n",
      "bc_util                                float64\n",
      "chargeoff_within_12_mths               float64\n",
      "delinq_amnt                            float64\n",
      "mo_sin_old_il_acct                     float64\n",
      "mo_sin_old_rev_tl_op                   float64\n",
      "mo_sin_rcnt_rev_tl_op                  float64\n",
      "mo_sin_rcnt_tl                         float64\n",
      "mort_acc                               float64\n",
      "mths_since_recent_bc                   float64\n",
      "mths_since_recent_bc_dlq               float64\n",
      "mths_since_recent_inq                  float64\n",
      "mths_since_recent_revol_delinq         float64\n",
      "num_accts_ever_120_pd                  float64\n",
      "num_actv_bc_tl                         float64\n",
      "num_actv_rev_tl                        float64\n",
      "num_bc_sats                            float64\n",
      "num_bc_tl                              float64\n",
      "num_il_tl                              float64\n",
      "num_op_rev_tl                          float64\n",
      "num_rev_accts                          float64\n",
      "num_rev_tl_bal_gt_0                    float64\n",
      "num_sats                               float64\n",
      "num_tl_120dpd_2m                       float64\n",
      "num_tl_30dpd                           float64\n",
      "num_tl_90g_dpd_24m                     float64\n",
      "num_tl_op_past_12m                     float64\n",
      "pct_tl_nvr_dlq                         float64\n",
      "percent_bc_gt_75                       float64\n",
      "pub_rec_bankruptcies                   float64\n",
      "tax_liens                              float64\n",
      "tot_hi_cred_lim                        float64\n",
      "total_bal_ex_mort                      float64\n",
      "total_bc_limit                         float64\n",
      "total_il_high_credit_limit             float64\n",
      "revol_bal_joint                        float64\n",
      "sec_app_fico_range_low                 float64\n",
      "sec_app_fico_range_high                float64\n",
      "sec_app_inq_last_6mths                 float64\n",
      "sec_app_mort_acc                       float64\n",
      "sec_app_open_acc                       float64\n",
      "sec_app_revol_util                     float64\n",
      "sec_app_open_act_il                    float64\n",
      "sec_app_num_rev_accts                  float64\n",
      "sec_app_chargeoff_within_12_mths       float64\n",
      "sec_app_collections_12_mths_ex_med     float64\n",
      "sec_app_mths_since_last_major_derog    float64\n",
      "disbursement_method                    object\n",
      "sec_length_of_cr                       float64\n",
      "length_of_cr                           float64\n",
      "dtypes: float64(89), int64(3), object(8)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('lending_club_ml.csv')\n",
    "df.drop(['id'], inplace=True, axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For normalizing\n",
    "\n",
    "numeric=[]\n",
    "\n",
    "for column in df:\n",
    "    if ((df[column].dtypes == 'float64') | (df[column].dtypes=='int64')):\n",
    "        numeric.append(column)\n",
    "numeric.remove('loan_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is basically the same code from loan_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if a loan was an indivdual loan then we will fill the all joint-realted features with its self\n",
    "\n",
    "df.application_type = df.application_type.apply(\n",
    "    lambda app_type: 1 if app_type == 'Individual' else 0)\n",
    "\n",
    "sec_list = ['sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_inq_last_6mths', 'sec_app_mort_acc',\n",
    "            'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths',\n",
    "            'sec_app_collections_12_mths_ex_med', 'sec_app_mths_since_last_major_derog', 'sec_app_open_act_il']\n",
    "joint_list = ['dti_joint', 'revol_bal_joint', 'annual_inc_joint']\n",
    "\n",
    "for secondary in sec_list:\n",
    "    df.loc[df.application_type ==\n",
    "           1][secondary] = df.loc[df.application_type == 1][secondary[8:]]\n",
    "\n",
    "for joint in joint_list:\n",
    "    df.loc[df.application_type ==\n",
    "           1][joint] = df.loc[df.application_type == 1][joint[:len(joint)-6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy variables for catergorical features\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(\n",
    "    df.sub_grade, prefix='sub_grade', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.home_ownership,\n",
    "                                   prefix='home_ownership', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.verification_status,\n",
    "                                   prefix='verification_status', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.purpose, prefix='purpose', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.verification_status_joint,\n",
    "                                   prefix='verification_status_joint', drop_first=True)], axis=1)\n",
    "\n",
    "df.disbursement_method = df.disbursement_method.apply(\n",
    "    lambda disburstment: 1 if disburstment == 'Cash' else 0)\n",
    "df.application_type = df.application_type.apply(\n",
    "    lambda app_type: 1 if app_type == 'Individual' else 0)\n",
    "\n",
    "df.drop(columns=['sub_grade', 'home_ownership', 'verification_status',\n",
    "                 'purpose', 'verification_status_joint'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill nans with the average\n",
    "\n",
    "df_avg=df\n",
    "\n",
    "for thing in df_avg:\n",
    "    if df_avg[thing].isnull().values.any():\n",
    "        df_avg[thing].fillna(np.mean(df_avg[thing]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def scoring(clf, x, y):\n",
    "    print('score: ', (clf.score(x, y)))\n",
    "    \n",
    "    #score adjusted for loan amount\n",
    "    print('balanced_accuracy_score: ', balanced_accuracy_score(y, clf.predict(x), sample_weight=x['loan_amnt']))\n",
    "\n",
    "    print(confusion_matrix(y, clf.predict(x)))\n",
    "    print('F1 score: ', f1_score(y, clf.predict(x)))\n",
    "    print('precision_score: ',precision_score(y, clf.predict(x)))\n",
    "    \n",
    "    #score adjusted for loan amount\n",
    "    print('average_precision_score: ', average_precision_score(y, clf.predict(x), average='weighted', sample_weight=x['loan_amnt']))\n",
    "    print('recall_score: ', recall_score(y, clf.predict(x)))\n",
    "    \n",
    "    #score adjusted for loan amount\n",
    "    print('roc: ', roc_auc_score(y, clf.predict_proba(x)[:, 1], average='weighted', sample_weight=x['loan_amnt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009446532149326\n",
      "balanced_accuracy_score:  0.5002377383591609\n",
      "[[    56 149621]\n",
      " [    73 602272]]\n",
      "F1 score:  0.8894625612336975\n",
      "precision_score:  0.8010075901757298\n",
      "average_precision_score:  0.7856673290807463\n",
      "recall_score:  0.9998788069959906\n",
      "roc:  0.6443311934446472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_avg = df_avg.drop(['loan_status','grade'], axis=1)\n",
    "y_avg = df_avg.loan_status\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit = LogisticRegression()\n",
    "\n",
    "logit.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit, X_avg_test, y_avg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "score:  0.9281962495778049\n",
      "balanced_accuracy_score:  0.8594551763957001\n",
      "[[110676  39001]\n",
      " [ 14997 587348]]\n",
      "F1 score:  0.9560525240621343\n",
      "precision_score:  0.9377327975298116\n",
      "average_precision_score:  0.9295429039132475\n",
      "recall_score:  0.9751023084776996\n",
      "roc:  0.9371857589959804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_avg = df_avg.drop(['loan_status','grade'], axis=1)\n",
    "y_avg = df_avg.loan_status\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_avg_train, y_avg_train)\n",
    "print('RANDOM FOREST')\n",
    "scoring(rf, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest vasts outperforms logistic regression. We will try to combine classifiers in an attempt to improve our scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "score:  0.9280845507179312\n",
      "balanced_accuracy_score:  0.8599772617037034\n",
      "[[110611  39066]\n",
      " [ 15016 587329]]\n",
      "F1 score:  0.9559858065986295\n",
      "precision_score:  0.9376336018007807\n",
      "average_precision_score:  0.9297987138523454\n",
      "recall_score:  0.9750707650930945\n",
      "roc:  0.9379349450913548\n"
     ]
    }
   ],
   "source": [
    "#with logit_predict_proba feature\n",
    "\n",
    "X_avg_pred = pd.DataFrame(logit.predict_proba(X_avg)[:,1],columns =['logit_predict_proba'])\n",
    "X_avg_ = pd.concat([X_avg,X_avg_pred],axis=1)\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg_, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_avg_train,y_avg_train)\n",
    "print('RANDOM FOREST')\n",
    "scoring(rf, X_avg_test, y_avg_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performs about the same, it maybe because there are too many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "score:  0.8077742406472151\n",
      "[[ 59983  89694]\n",
      " [ 54864 547481]]\n",
      "F1 score:  0.8833758228991868\n",
      "precision_score:  0.8592317652136383\n",
      "recall_score:  0.9089159866853713\n",
      "roc:  0.7816482831604685\n"
     ]
    }
   ],
   "source": [
    "#just the predict_proba feature\n",
    "df_rf = pd.concat([X_avg_pred,y_avg],axis=1)\n",
    "\n",
    "X = pd.DataFrame(df_rf['logit_predict_proba'])\n",
    "y = pd.DataFrame(df_rf['loan_status'])\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_avg_train,y_avg_train)\n",
    "print('RANDOM FOREST')\n",
    "print('score: ', (rf.score(X_avg_test, y_avg_test)))\n",
    "    \n",
    "#print('balanced_accuracy_score: ', balanced_accuracy_score(y, clf.predict(x), sample_weight=x['loan_amnt']))\n",
    "\n",
    "print(confusion_matrix(y_avg_test, rf.predict(X_avg_test)))\n",
    "print('F1 score: ', f1_score(y_avg_test, rf.predict(X_avg_test)))\n",
    "print('precision_score: ',precision_score(y_avg_test, rf.predict(X_avg_test)))\n",
    "    \n",
    "#print('average_precision_score: ', average_precision_score(y, clf.predict(x), average='weighted', sample_weight=x['loan_amnt']))\n",
    "print('recall_score: ', recall_score(y_avg_test, rf.predict(X_avg_test)))\n",
    "    \n",
    "print('roc: ', roc_auc_score(y_avg_test, rf.predict_proba(X_avg_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just the logit results as a feature resulted in a much lower score. There were much more false positives and false negatives compared to the massive feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.5913444021584475\n",
      "balanced_accuracy_score:  0.6140717696508232\n",
      "[[ 97559  52118]\n",
      " [255200 347145]]\n",
      "F1 score:  0.6931753739986102\n",
      "precision_score:  0.8694644883197291\n",
      "average_precision_score:  0.8282011180636957\n",
      "recall_score:  0.5763225394084786\n",
      "roc:  0.6630771823758567\n"
     ]
    }
   ],
   "source": [
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit_balanced = LogisticRegression(class_weight = 'balanced')\n",
    "\n",
    "logit_balanced.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_balanced, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009446532149326\n",
      "balanced_accuracy_score:  0.5002377383591609\n",
      "[[    56 149621]\n",
      " [    73 602272]]\n",
      "F1 score:  0.8894625612336975\n",
      "precision_score:  0.8010075901757298\n",
      "average_precision_score:  0.7856673290807463\n",
      "recall_score:  0.9998788069959906\n",
      "roc:  0.6443311934446472\n"
     ]
    }
   ],
   "source": [
    "#trying with nans filled with 0\n",
    "\n",
    "df_0 = df.fillna(0)\n",
    "\n",
    "X_0 = df_0.drop(['loan_status','grade'], axis=1)\n",
    "y_0 = df_0.loan_status\n",
    "\n",
    "X_0_train, X_0_test, y_0_train, y_0_test = train_test_split(\n",
    "X_0, y_0, test_size=0.3, random_state=42)\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_0_train, y_0_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit, X_0_test, y_0_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did not even matter, will try normalizing then hyper tuning 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8008635385666909\n",
      "balanced_accuracy_score:  0.5006189990261432\n",
      "[[   152 149525]\n",
      " [   230 602115]]\n",
      "F1 score:  0.8893968544703228\n",
      "precision_score:  0.8010683305837901\n",
      "average_precision_score:  0.7857958153749027\n",
      "recall_score:  0.9996181590284637\n",
      "roc:  0.6554825379834309\n"
     ]
    }
   ],
   "source": [
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit_c_0001 = LogisticRegression(C=.0001)\n",
    "\n",
    "logit_c_0001.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_0001, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009300259832824\n",
      "balanced_accuracy_score:  0.5004424141715003\n",
      "[[   103 149574]\n",
      " [   131 602214]]\n",
      "F1 score:  0.8894458668387817\n",
      "precision_score:  0.8010423151207521\n",
      "average_precision_score:  0.7857363003694248\n",
      "recall_score:  0.9997825166640381\n",
      "roc:  0.6514327242621893\n"
     ]
    }
   ],
   "source": [
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit_c_01 = LogisticRegression(C=.01)\n",
    "\n",
    "logit_c_01.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_01, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.800956620949919\n",
      "balanced_accuracy_score:  0.5002725321329511\n",
      "[[    60 149617]\n",
      " [    68 602277]]\n",
      "F1 score:  0.8894692886558428\n",
      "precision_score:  0.8010131747294167\n",
      "average_precision_score:  0.7856790529684031\n",
      "recall_score:  0.9998871078866762\n",
      "roc:  0.6449016175844058\n"
     ]
    }
   ],
   "source": [
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit_c_1 = LogisticRegression(C=.1)\n",
    "\n",
    "logit_c_1.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_1, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009419937182689\n",
      "balanced_accuracy_score:  0.5002239402258125\n",
      "[[    57 149620]\n",
      " [    76 602269]]\n",
      "F1 score:  0.8894607578896999\n",
      "precision_score:  0.8010078615327528\n",
      "average_precision_score:  0.7856626798467449\n",
      "recall_score:  0.9998738264615793\n",
      "roc:  0.640807180050564\n"
     ]
    }
   ],
   "source": [
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit_c_10 = LogisticRegression(C=10)\n",
    "\n",
    "logit_c_10.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_10, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009326854799461\n",
      "balanced_accuracy_score:  0.5002524657712254\n",
      "[[    64 149613]\n",
      " [    90 602255]]\n",
      "F1 score:  0.8894538746858877\n",
      "precision_score:  0.8010116137407098\n",
      "average_precision_score:  0.7856722914932446\n",
      "recall_score:  0.9998505839676597\n",
      "roc:  0.6424014797915372\n"
     ]
    }
   ],
   "source": [
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit_c_100 = LogisticRegression(C=100)\n",
    "\n",
    "logit_c_100.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_100, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009180582482959\n",
      "balanced_accuracy_score:  0.500493372619013\n",
      "[[   112 149565]\n",
      " [   149 602196]]\n",
      "F1 score:  0.8894370160090865\n",
      "precision_score:  0.801047141312199\n",
      "average_precision_score:  0.7857534741417198\n",
      "recall_score:  0.99975263345757\n",
      "roc:  0.65190125034441\n"
     ]
    }
   ],
   "source": [
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit_c_1000 = LogisticRegression(C=1000)\n",
    "\n",
    "logit_c_1000.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_1000, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009300259832824\n",
      "balanced_accuracy_score:  0.5003103162678659\n",
      "[[    74 149603]\n",
      " [   102 602243]]\n",
      "F1 score:  0.8894506018722618\n",
      "precision_score:  0.8010190916756889\n",
      "average_precision_score:  0.7856917848676329\n",
      "recall_score:  0.9998306618300143\n",
      "roc:  0.6493744955895291\n"
     ]
    }
   ],
   "source": [
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit_c_10000 = LogisticRegression(C=10000)\n",
    "\n",
    "logit_c_10000.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_10000, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.model_selection import GridSearchCV\\n\\nparameters = {'C':np.logspace(np.log10(.0001),np.log10(10000),5)}\\n\\nlogit_cv = GridSearchCV(logit, parameters, cv=5)\\n\\nlogit_cv.fit(X_avg,y_avg)\\n\\nlogit_cv.best_score_\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':np.logspace(np.log10(.0001),np.log10(10000),5)}\n",
    "\n",
    "logit_cv = GridSearchCV(logit, parameters, cv=5)\n",
    "\n",
    "logit_cv.fit(X_avg,y_avg)\n",
    "\n",
    "logit_cv.best_score_'''\n",
    "#took too long to run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8044511995659701\n",
      "balanced_accuracy_score:  0.8542232944913832\n",
      "[[ 11325 138352]\n",
      " [  8705 593640]]\n",
      "F1 score:  0.889790210419107\n",
      "precision_score:  0.8109924698630586\n",
      "average_precision_score:  86.64655048676774\n",
      "recall_score:  0.9855481493164217\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x is neither increasing nor decreasing : [0. 0. 0. ... 1. 1. 1.].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-894eec8aabc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mlogit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_avg_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_avg_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LOGISTIC REGRESSION'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mscoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_avg_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_avg_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-c4f77e71717e>\u001b[0m in \u001b[0;36mscoring\u001b[1;34m(clf, x, y)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#score adjusted for loan amount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'roc: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loan_amnt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    354\u001b[0m     return _average_binary_score(\n\u001b[0;32m    355\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                                 sample_weight=sample_weight)\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             raise ValueError(\"Expected max_frp in range ]0, 1], got: %r\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mauc\u001b[1;34m(x, y, reorder)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                 raise ValueError(\"x is neither increasing nor decreasing \"\n\u001b[1;32m--> 119\u001b[1;33m                                  \": {}.\".format(x))\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0marea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirection\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrapz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x is neither increasing nor decreasing : [0. 0. 0. ... 1. 1. 1.]."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "trans_norm = StandardScaler(copy = False)\n",
    "\n",
    "df_avg=df\n",
    "\n",
    "for thing in df_avg:\n",
    "    if df_avg[thing].isnull().values.any():\n",
    "        df_avg[thing].fillna(np.mean(df_avg[thing]), inplace=True)\n",
    "        \n",
    "X_avg = df_avg.drop(['loan_status','grade'], axis=1)\n",
    "y_avg = df_avg.loan_status\n",
    "\n",
    "for number in numeric:\n",
    "    X_avg[number] = trans_norm.fit_transform(np.array(X_avg[number]).reshape(-1,1))\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit, X_avg_test, y_avg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = LogisticRegressionCV(cv=5,solver='liblinear', Cs=np.logspace(np.log10(.0001),np.log10(10000),5),scoring='roc_auc')\n",
    "\n",
    "clf.fit(X_avg,y_avg)\n",
    "print(clf.scores_)\n",
    "\n",
    "clf.fit(X_0,y_0)\n",
    "print(clf.scores_)'''\n",
    "#takes forever to run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
