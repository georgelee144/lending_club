{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('lending_club_ml.csv')\n",
    "df.drop(['id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating columns for features that had more than 2 outcomes\n",
    "# I have decided to use subgrade and not grade as these are suppose to be similar features but, subgrade is more granular\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(\n",
    "    df.sub_grade, prefix='sub_grade', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.home_ownership,\n",
    "                                   prefix='home_ownership', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.verification_status,\n",
    "                                   prefix='verification_status', drop_first=True)], axis=1)\n",
    "df = pd.concat(\n",
    "    [df, pd.get_dummies(df.purpose, prefix='purpose', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.verification_status_joint,\n",
    "                                   prefix='verification_status_joint', drop_first=True)], axis=1)\n",
    "\n",
    "df.drop(columns=['sub_grade', 'home_ownership', 'verification_status',\n",
    "                 'purpose', 'verification_status_joint'], inplace=True)\n",
    "\n",
    "\n",
    "# conversions for features that only had 2 outcomes\n",
    "\n",
    "df.disbursement_method = df.disbursement_method.apply(\n",
    "    lambda disburstment: 1 if disburstment == 'Cash' else 0)\n",
    "\n",
    "df.application_type = df.application_type.apply(\n",
    "    lambda app_type: 1 if app_type == 'Individual' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all0 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2506738 entries, 0 to 2506737\n",
      "Columns: 148 entries, loan_amnt to verification_status_joint_Verified\n",
      "dtypes: float64(89), int64(5), object(1), uint8(53)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "# if borrower is an indivudal then their secondary features are filled with their single counterpart\n",
    "\n",
    "sec_list = ['sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_inq_last_6mths', 'sec_app_mort_acc',\n",
    "            'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_act_il','sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths',\n",
    "            'sec_app_collections_12_mths_ex_med', 'sec_app_mths_since_last_major_derog']\n",
    "joint_list = ['dti_joint', 'revol_bal_joint', 'annual_inc_joint']\n",
    "\n",
    "for secondary in sec_list:\n",
    "    df.loc[df.application_type == 1,secondary] = df.loc[df.application_type == 1][secondary[8:]]\n",
    "\n",
    "\n",
    "for joint in joint_list:\n",
    "    df.loc[df.application_type == 1,joint] = df.loc[df.application_type == 1][joint[:len(joint)-6]]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill all nans with 0\n",
    "df.fillna(0, inplace=True)\n",
    "df_all0.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def scoring(clf, x, y):\n",
    "    \n",
    "    #Baseline\n",
    "    print('Loan passing rate:', np.mean(y))\n",
    "    print('Balanced loan passing rate:', np.average(y, weights=x['loan_amnt']))\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    print('score: ', clf.score(x, y))\n",
    "    # score adjusted for loan amount\n",
    "    print('balanced_accuracy_score: ', balanced_accuracy_score(\n",
    "        y, clf.predict(x), sample_weight=x['loan_amnt']))\n",
    "\n",
    "    print(confusion_matrix(y, clf.predict(x)))\n",
    "    \n",
    "    print('F1 score: ', f1_score(y, clf.predict(x)))\n",
    "    \n",
    "    print('precision_score: ', precision_score(y, clf.predict(x)))\n",
    "\n",
    "    # score adjusted for loan amount\n",
    "    print('average_precision_score: ', average_precision_score(\n",
    "        y, clf.predict(x), average='weighted', sample_weight=x['loan_amnt']))\n",
    "    \n",
    "    print('recall_score: ', recall_score(y, clf.predict(x)))\n",
    "\n",
    "    print('roc: ', roc_auc_score(y, clf.predict_proba(x)[:, 1]))\n",
    "\n",
    "    # score adjusted for loan amount\n",
    "    print('roc_weighted: ', roc_auc_score(y, clf.predict_proba(x)[\n",
    "          :, 1], average='weighted', sample_weight=x['loan_amnt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan passing rate: 0.8009672589365736\n",
      "Balanced loan passing rate: 0.7855872316459166\n",
      "\n",
      "\n",
      "score:  0.9414006505128839\n",
      "balanced_accuracy_score:  0.8601610947497798\n",
      "[[108017  41660]\n",
      " [  2408 599937]]\n",
      "F1 score:  0.9645739110022814\n",
      "precision_score:  0.9350682749451759\n",
      "average_precision_score:  0.9292143144031701\n",
      "recall_score:  0.9960022910458293\n",
      "roc:  0.964646992831969\n",
      "roc_weighted:  0.9653540974978726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['grade','loan_status'], axis=1)\n",
    "y = df.loan_status\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_best = RandomForestClassifier(criterion= 'entropy', n_estimators= 101)\n",
    "rf_best.fit(X_train, y_train)\n",
    "    \n",
    "scoring(rf_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "Loan passing rate: 0.8009672589365736\n",
      "Balanced loan passing rate: 0.7855872316459166\n",
      "\n",
      "\n",
      "score:  0.9413900125262293\n",
      "balanced_accuracy_score:  0.8598727062980376\n",
      "[[107973  41704]\n",
      " [  2372 599973]]\n",
      "F1 score:  0.9645697584126326\n",
      "precision_score:  0.9350077998743916\n",
      "average_precision_score:  0.9290774560082338\n",
      "recall_score:  0.9960620574587653\n",
      "roc:  0.9645527780415752\n",
      "roc_weighted:  0.9652885481246404\n"
     ]
    }
   ],
   "source": [
    "X0 = df_all0.drop(['grade','loan_status'], axis=1)\n",
    "y0 = df_all0.loan_status\n",
    "\n",
    "X0_train, X0_test, y0_train, y0_test = train_test_split(X0, y0, test_size=0.3, random_state=42)\n",
    "\n",
    "rf0_best = RandomForestClassifier(criterion= 'entropy', n_estimators= 101)\n",
    "rf0_best.fit(X0_train, y0_train)\n",
    "    \n",
    "print('RANDOM FOREST')\n",
    "\n",
    "scoring(rf0_best, X0_test, y0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan passing rate: 0.8009672589365736\n",
      "Balanced loan passing rate: 0.7855872316459166\n",
      "\n",
      "\n",
      "score:  0.827248404966876\n",
      "balanced_accuracy_score:  0.5811965211185268\n",
      "[[ 21837 127840]\n",
      " [  2073 600272]]\n",
      "F1 score:  0.902354604470494\n",
      "precision_score:  0.8244226163007888\n",
      "average_precision_score:  0.8139324727361922\n",
      "recall_score:  0.9965584507217624\n",
      "roc:  0.85017992117754\n",
      "roc_weighted:  0.8466890413326119\n",
      "Loan passing rate: 0.8009672589365736\n",
      "Balanced loan passing rate: 0.7855872316459166\n",
      "\n",
      "\n",
      "score:  0.9410057152583302\n",
      "balanced_accuracy_score:  0.8561630060301875\n",
      "[[106874  42803]\n",
      " [  1562 600783]]\n",
      "F1 score:  0.9643920891285312\n",
      "precision_score:  0.9334929597598456\n",
      "average_precision_score:  0.9272818174121961\n",
      "recall_score:  0.9974068017498278\n",
      "roc:  0.96258098436719\n",
      "roc_weighted:  0.9634511096360182\n"
     ]
    }
   ],
   "source": [
    "scoring(rf_best, X0_test, y0_test)\n",
    "scoring(rf0_best, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
