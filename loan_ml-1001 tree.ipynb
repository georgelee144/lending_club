{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('lending_club_ml.csv')\n",
    "df.drop(['id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating columns for features that had more than 2 outcomes\n",
    "# I have decided to use subgrade and not grade as these are suppose to be similar features but, subgrade is more granular\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(\n",
    "    df.sub_grade, prefix='sub_grade', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.home_ownership,\n",
    "                                   prefix='home_ownership', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.verification_status,\n",
    "                                   prefix='verification_status', drop_first=True)], axis=1)\n",
    "df = pd.concat(\n",
    "    [df, pd.get_dummies(df.purpose, prefix='purpose', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.verification_status_joint,\n",
    "                                   prefix='verification_status_joint', drop_first=True)], axis=1)\n",
    "\n",
    "df.drop(columns=['sub_grade', 'home_ownership', 'verification_status',\n",
    "                 'purpose', 'verification_status_joint'], inplace=True)\n",
    "\n",
    "\n",
    "# conversions for features that only had 2 outcomes\n",
    "\n",
    "df.disbursement_method = df.disbursement_method.apply(\n",
    "    lambda disburstment: 1 if disburstment == 'Cash' else 0)\n",
    "\n",
    "df.application_type = df.application_type.apply(\n",
    "    lambda app_type: 1 if app_type == 'Individual' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2506738 entries, 0 to 2506737\n",
      "Columns: 148 entries, loan_amnt to verification_status_joint_Verified\n",
      "dtypes: float64(89), int64(5), object(1), uint8(53)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "# if borrower is an indivudal then their secondary features are filled with their single counterpart\n",
    "\n",
    "sec_list = ['sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_inq_last_6mths', 'sec_app_mort_acc',\n",
    "            'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_act_il','sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths',\n",
    "            'sec_app_collections_12_mths_ex_med', 'sec_app_mths_since_last_major_derog']\n",
    "joint_list = ['dti_joint', 'revol_bal_joint', 'annual_inc_joint']\n",
    "\n",
    "for secondary in sec_list:\n",
    "    df.loc[df.application_type == 1,secondary] = df.loc[df.application_type == 1][secondary[8:]]\n",
    "\n",
    "\n",
    "for joint in joint_list:\n",
    "    df.loc[df.application_type == 1,joint] = df.loc[df.application_type == 1][joint[:len(joint)-6]]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill all nans with 0\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def scoring(clf, x, y):\n",
    "    \n",
    "    #Baseline\n",
    "    print('Loan passing rate:', np.mean(y))\n",
    "    print('Balanced loan passing rate:', np.average(y, weights=x['loan_amnt']))\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    print('score: ', clf.score(x, y))\n",
    "    # score adjusted for loan amount\n",
    "    print('balanced_accuracy_score: ', balanced_accuracy_score(\n",
    "        y, clf.predict(x), sample_weight=x['loan_amnt']))\n",
    "\n",
    "    print(confusion_matrix(y, clf.predict(x)))\n",
    "    \n",
    "    print('F1 score: ', f1_score(y, clf.predict(x)))\n",
    "    \n",
    "    print('precision_score: ', precision_score(y, clf.predict(x)))\n",
    "\n",
    "    # score adjusted for loan amount\n",
    "    print('average_precision_score: ', average_precision_score(\n",
    "        y, clf.predict(x), average='weighted', sample_weight=x['loan_amnt']))\n",
    "    \n",
    "    print('recall_score: ', recall_score(y, clf.predict(x)))\n",
    "\n",
    "    print('roc: ', roc_auc_score(y, clf.predict_proba(x)[:, 1]))\n",
    "\n",
    "    # score adjusted for loan amount\n",
    "    print('roc_weighted: ', roc_auc_score(y, clf.predict_proba(x)[\n",
    "          :, 1], average='weighted', sample_weight=x['loan_amnt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "Loan passing rate: 0.8009672589365736\n",
      "Balanced loan passing rate: 0.7855872316459166\n",
      "\n",
      "\n",
      "score:  0.9415203278627488\n",
      "balanced_accuracy_score:  0.8587148931397046\n",
      "[[107593  42084]\n",
      " [  1894 600451]]\n",
      "F1 score:  0.9646729001992159\n",
      "precision_score:  0.9345031788151619\n",
      "average_precision_score:  0.9285033135536983\n",
      "recall_score:  0.9968556226083058\n",
      "roc:  0.9679851576576207\n",
      "roc_weighted:  0.9684727550004013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['grade','loan_status'], axis=1)\n",
    "y = df.loan_status\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_best = RandomForestClassifier(criterion= 'entropy', n_estimators= 1001)\n",
    "rf_best.fit(X_train, y_train)\n",
    "    \n",
    "print('RANDOM FOREST')\n",
    "scoring(rf_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_1001.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(rf_best, 'rf_1001.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-db79f4a4c72f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rf_1001.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('rf_1001.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_best, f)\n",
    "#need more ram"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
