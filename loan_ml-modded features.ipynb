{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('lending_club_ml.csv')\n",
    "df.drop(['id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating columns for features that had more than 2 outcomes\n",
    "# I have decided to use subgrade and not grade as these are suppose to be similar features but, subgrade is more granular\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(\n",
    "    df.sub_grade, prefix='sub_grade', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.home_ownership,\n",
    "                                   prefix='home_ownership', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.verification_status,\n",
    "                                   prefix='verification_status', drop_first=True)], axis=1)\n",
    "df = pd.concat(\n",
    "    [df, pd.get_dummies(df.purpose, prefix='purpose', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.verification_status_joint,\n",
    "                                   prefix='verification_status_joint', drop_first=True)], axis=1)\n",
    "\n",
    "df.drop(columns=['sub_grade', 'home_ownership', 'verification_status',\n",
    "                 'purpose', 'verification_status_joint'], inplace=True)\n",
    "\n",
    "\n",
    "# conversions for features that only had 2 outcomes\n",
    "\n",
    "df.disbursement_method = df.disbursement_method.apply(\n",
    "    lambda disburstment: 1 if disburstment == 'Cash' else 0)\n",
    "\n",
    "df.application_type = df.application_type.apply(\n",
    "    lambda app_type: 1 if app_type == 'Individual' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill all nans with 0\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def scoring(clf, x, y):\n",
    "    \n",
    "    #Baseline\n",
    "    print('Loan passing rate:', np.mean(y))\n",
    "    print('Balanced loan passing rate:', np.average(y, weights=x['loan_amnt']))\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    print('score: ', clf.score(x, y))\n",
    "    # score adjusted for loan amount\n",
    "    print('balanced_accuracy_score: ', balanced_accuracy_score(\n",
    "        y, clf.predict(x), sample_weight=x['loan_amnt']))\n",
    "\n",
    "    print(confusion_matrix(y, clf.predict(x)))\n",
    "    \n",
    "    print('F1 score: ', f1_score(y, clf.predict(x)))\n",
    "    \n",
    "    print('precision_score: ', precision_score(y, clf.predict(x)))\n",
    "\n",
    "    # score adjusted for loan amount\n",
    "    print('average_precision_score: ', average_precision_score(\n",
    "        y, clf.predict(x), average='weighted', sample_weight=x['loan_amnt']))\n",
    "    \n",
    "    print('recall_score: ', recall_score(y, clf.predict(x)))\n",
    "\n",
    "    print('roc: ', roc_auc_score(y, clf.predict_proba(x)[:, 1]))\n",
    "\n",
    "    # score adjusted for loan amount\n",
    "    print('roc_weighted: ', roc_auc_score(y, clf.predict_proba(x)[\n",
    "          :, 1], average='weighted', sample_weight=x['loan_amnt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "Loan passing rate: 0.8009672589365736\n",
      "Balanced loan passing rate: 0.7855872316459166\n",
      "\n",
      "\n",
      "score:  0.9414963923927757\n",
      "balanced_accuracy_score:  0.8599558014707467\n",
      "[[107967  41710]\n",
      " [  2286 600059]]\n",
      "F1 score:  0.9646366812044556\n",
      "precision_score:  0.9350077675923891\n",
      "average_precision_score:  0.9291126361304757\n",
      "recall_score:  0.9962048327785571\n",
      "roc:  0.9647346881425156\n",
      "roc_weighted:  0.965500586336011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['grade','loan_status'], axis=1)\n",
    "y = df.loan_status\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_best = RandomForestClassifier(criterion= 'entropy', n_estimators= 101)\n",
    "rf_best.fit(X_train, y_train)\n",
    "    \n",
    "print('RANDOM FOREST')\n",
    "scoring(rf_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modded = df[['loan_status','loan_amnt','annual_inc','installment','int_rate','fico_range_high']]\n",
    "\n",
    "df_modded['installment_to_annual_inc'] =  df_modded.annual_inc/df_modded.installment * 12\n",
    "df_modded.drop(['annual_inc','installment'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "Loan passing rate: 0.8009672589365736\n",
      "Balanced loan passing rate: 0.7855872316459166\n",
      "\n",
      "\n",
      "score:  0.9088151676413722\n",
      "balanced_accuracy_score:  0.8276923489943548\n",
      "[[101746  47931]\n",
      " [ 20642 581703]]\n",
      "F1 score:  0.9443391486380854\n",
      "precision_score:  0.9238748225159378\n",
      "average_precision_score:  0.914873392617448\n",
      "recall_score:  0.9657306028936905\n",
      "roc:  0.913568553286728\n",
      "roc_weighted:  0.9160013070955311\n"
     ]
    }
   ],
   "source": [
    "Xm = df_modded.drop(['loan_status'], axis=1)\n",
    "ym = df_modded.loan_status\n",
    "\n",
    "Xm_train, Xm_test, ym_train, ym_test = train_test_split(Xm, ym, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_m = RandomForestClassifier(criterion= 'entropy', n_estimators= 101)\n",
    "rf_m.fit(Xm_train, ym_train)\n",
    "    \n",
    "print('RANDOM FOREST')\n",
    "scoring(rf_m, Xm_test, ym_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
