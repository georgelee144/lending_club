{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is best thought of as a \"appendix\" to loan_ml. I am trying to investigate the usefulness of a logistic regression (logit) since it seems to have abysmal to no predictive value.\n",
    "\n",
    "Here I will try to find if I improve the logit function through a combination of preprocessing and hyper parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2506738 entries, 0 to 2506737\n",
      "Data columns (total 100 columns):\n",
      "loan_amnt                              float64\n",
      "term                                   int64\n",
      "int_rate                               float64\n",
      "installment                            float64\n",
      "grade                                  object\n",
      "sub_grade                              object\n",
      "emp_length                             int64\n",
      "home_ownership                         object\n",
      "annual_inc                             float64\n",
      "verification_status                    object\n",
      "loan_status                            int64\n",
      "purpose                                object\n",
      "dti                                    float64\n",
      "delinq_2yrs                            float64\n",
      "fico_range_low                         float64\n",
      "fico_range_high                        float64\n",
      "inq_last_6mths                         float64\n",
      "mths_since_last_delinq                 float64\n",
      "mths_since_last_record                 float64\n",
      "open_acc                               float64\n",
      "pub_rec                                float64\n",
      "revol_bal                              float64\n",
      "revol_util                             float64\n",
      "total_acc                              float64\n",
      "collections_12_mths_ex_med             float64\n",
      "mths_since_last_major_derog            float64\n",
      "application_type                       object\n",
      "annual_inc_joint                       float64\n",
      "dti_joint                              float64\n",
      "verification_status_joint              object\n",
      "acc_now_delinq                         float64\n",
      "tot_coll_amt                           float64\n",
      "tot_cur_bal                            float64\n",
      "open_acc_6m                            float64\n",
      "open_act_il                            float64\n",
      "open_il_12m                            float64\n",
      "open_il_24m                            float64\n",
      "mths_since_rcnt_il                     float64\n",
      "total_bal_il                           float64\n",
      "il_util                                float64\n",
      "open_rv_12m                            float64\n",
      "open_rv_24m                            float64\n",
      "max_bal_bc                             float64\n",
      "all_util                               float64\n",
      "total_rev_hi_lim                       float64\n",
      "inq_fi                                 float64\n",
      "total_cu_tl                            float64\n",
      "inq_last_12m                           float64\n",
      "acc_open_past_24mths                   float64\n",
      "avg_cur_bal                            float64\n",
      "bc_open_to_buy                         float64\n",
      "bc_util                                float64\n",
      "chargeoff_within_12_mths               float64\n",
      "delinq_amnt                            float64\n",
      "mo_sin_old_il_acct                     float64\n",
      "mo_sin_old_rev_tl_op                   float64\n",
      "mo_sin_rcnt_rev_tl_op                  float64\n",
      "mo_sin_rcnt_tl                         float64\n",
      "mort_acc                               float64\n",
      "mths_since_recent_bc                   float64\n",
      "mths_since_recent_bc_dlq               float64\n",
      "mths_since_recent_inq                  float64\n",
      "mths_since_recent_revol_delinq         float64\n",
      "num_accts_ever_120_pd                  float64\n",
      "num_actv_bc_tl                         float64\n",
      "num_actv_rev_tl                        float64\n",
      "num_bc_sats                            float64\n",
      "num_bc_tl                              float64\n",
      "num_il_tl                              float64\n",
      "num_op_rev_tl                          float64\n",
      "num_rev_accts                          float64\n",
      "num_rev_tl_bal_gt_0                    float64\n",
      "num_sats                               float64\n",
      "num_tl_120dpd_2m                       float64\n",
      "num_tl_30dpd                           float64\n",
      "num_tl_90g_dpd_24m                     float64\n",
      "num_tl_op_past_12m                     float64\n",
      "pct_tl_nvr_dlq                         float64\n",
      "percent_bc_gt_75                       float64\n",
      "pub_rec_bankruptcies                   float64\n",
      "tax_liens                              float64\n",
      "tot_hi_cred_lim                        float64\n",
      "total_bal_ex_mort                      float64\n",
      "total_bc_limit                         float64\n",
      "total_il_high_credit_limit             float64\n",
      "revol_bal_joint                        float64\n",
      "sec_app_fico_range_low                 float64\n",
      "sec_app_fico_range_high                float64\n",
      "sec_app_inq_last_6mths                 float64\n",
      "sec_app_mort_acc                       float64\n",
      "sec_app_open_acc                       float64\n",
      "sec_app_revol_util                     float64\n",
      "sec_app_open_act_il                    float64\n",
      "sec_app_num_rev_accts                  float64\n",
      "sec_app_chargeoff_within_12_mths       float64\n",
      "sec_app_collections_12_mths_ex_med     float64\n",
      "sec_app_mths_since_last_major_derog    float64\n",
      "disbursement_method                    object\n",
      "sec_length_of_cr                       float64\n",
      "length_of_cr                           float64\n",
      "dtypes: float64(89), int64(3), object(8)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('lending_club_ml.csv')\n",
    "df.drop(['id'], inplace=True, axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For normalizing\n",
    "\n",
    "numeric=[]\n",
    "\n",
    "for column in df:\n",
    "    if ((df[column].dtypes == 'float64') | (df[column].dtypes=='int64')):\n",
    "        numeric.append(column)\n",
    "numeric.remove('loan_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is basically the same code from loan_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if a loan was an indivdual loan then we will fill the all joint-realted features with its self\n",
    "\n",
    "df.application_type = df.application_type.apply(\n",
    "    lambda app_type: 1 if app_type == 'Individual' else 0)\n",
    "\n",
    "sec_list = ['sec_app_fico_range_low', 'sec_app_fico_range_high', 'sec_app_inq_last_6mths', 'sec_app_mort_acc',\n",
    "            'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths',\n",
    "            'sec_app_collections_12_mths_ex_med', 'sec_app_mths_since_last_major_derog', 'sec_app_open_act_il']\n",
    "joint_list = ['dti_joint', 'revol_bal_joint', 'annual_inc_joint']\n",
    "\n",
    "for secondary in sec_list:\n",
    "    df.loc[df.application_type ==\n",
    "           1][secondary] = df.loc[df.application_type == 1][secondary[8:]]\n",
    "\n",
    "for joint in joint_list:\n",
    "    df.loc[df.application_type ==\n",
    "           1][joint] = df.loc[df.application_type == 1][joint[:len(joint)-6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy variables for catergorical features\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(\n",
    "    df.sub_grade, prefix='sub_grade', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.home_ownership,\n",
    "                                   prefix='home_ownership', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.verification_status,\n",
    "                                   prefix='verification_status', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.purpose, prefix='purpose', drop_first=True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df.verification_status_joint,\n",
    "                                   prefix='verification_status_joint', drop_first=True)], axis=1)\n",
    "\n",
    "df.disbursement_method = df.disbursement_method.apply(\n",
    "    lambda disburstment: 1 if disburstment == 'Cash' else 0)\n",
    "df.application_type = df.application_type.apply(\n",
    "    lambda app_type: 1 if app_type == 'Individual' else 0)\n",
    "\n",
    "df.drop(columns=['sub_grade', 'home_ownership', 'verification_status',\n",
    "                 'purpose', 'verification_status_joint'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill nans with the average\n",
    "\n",
    "df_avg=df\n",
    "\n",
    "for thing in df_avg:\n",
    "    if df_avg[thing].isnull().values.any():\n",
    "        df_avg[thing].fillna(np.mean(df_avg[thing]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def scoring(clf, x, y):\n",
    "    print('score: ', (clf.score(x, y)))\n",
    "    \n",
    "    #score adjusted for loan amount\n",
    "    print('balanced_accuracy_score: ', balanced_accuracy_score(y, clf.predict(x), sample_weight=x['loan_amnt']))\n",
    "\n",
    "    print(confusion_matrix(y, clf.predict(x)))\n",
    "    print('F1 score: ', f1_score(y, clf.predict(x)))\n",
    "    print('precision_score: ',precision_score(y, clf.predict(x)))\n",
    "    \n",
    "    #score adjusted for loan amount\n",
    "    print('average_precision_score: ', average_precision_score(y, clf.predict(x), average='weighted', sample_weight=x['loan_amnt']))\n",
    "    print('recall_score: ', recall_score(y, clf.predict(x)))\n",
    "    \n",
    "    #score adjusted for loan amount\n",
    "    print('roc: ', roc_auc_score(y, clf.predict_proba(x)[:, 1], average='weighted', sample_weight=x['loan_amnt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_avg = df_avg.drop(['loan_status','grade'], axis=1)\n",
    "y_avg = df_avg.loan_status\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc =SVC()\n",
    "\n",
    "svc.fit(X_avg_train, y_avg_train)\n",
    "print('SUPPORT VECTOR MACHINE')\n",
    "scoring(svc, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009446532149326\n",
      "balanced_accuracy_score:  0.5002377383591609\n",
      "[[    56 149621]\n",
      " [    73 602272]]\n",
      "F1 score:  0.8894625612336975\n",
      "precision_score:  0.8010075901757298\n",
      "average_precision_score:  0.7856673290807463\n",
      "recall_score:  0.9998788069959906\n",
      "roc:  0.6443311934446472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression()\n",
    "\n",
    "logit.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit, X_avg_test, y_avg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOSTING\n",
      "score:  0.8049086329921199\n",
      "balanced_accuracy_score:  0.5358404711727079\n",
      "[[ 11438 138239]\n",
      " [  8474 593871]]\n",
      "F1 score:  0.8900577389271276\n",
      "precision_score:  0.8111772821024164\n",
      "average_precision_score:  0.797853182289571\n",
      "recall_score:  0.985931650466095\n",
      "roc:  0.7279544927350117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_avg_train, y_avg_train)\n",
    "print('GRADIENT BOOSTING')\n",
    "scoring(gbm, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOSTING\n",
      "score:  0.8049046437471244\n",
      "balanced_accuracy_score:  0.5351824150543527\n",
      "[[ 11110 138567]\n",
      " [  8149 594196]]\n",
      "F1 score:  0.8901092645688589\n",
      "precision_score:  0.8108979301629585\n",
      "average_precision_score:  0.7976243564954537\n",
      "recall_score:  0.986471208360657\n",
      "roc:  0.7282057251814118\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingClassifier(loss = 'exponential')\n",
    "gbm.fit(X_avg_train, y_avg_train)\n",
    "print('GRADIENT BOOSTING')\n",
    "scoring(gbm, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "score:  0.9287254894138736\n",
      "balanced_accuracy_score:  0.8601530714597598\n",
      "[[110724  38953]\n",
      " [ 14647 587698]]\n",
      "F1 score:  0.9563871648076967\n",
      "precision_score:  0.9378394034318943\n",
      "average_precision_score:  0.9298508790838188\n",
      "recall_score:  0.9756833708256896\n",
      "roc:  0.9370065786881925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_avg = df_avg.drop(['loan_status','grade'], axis=1)\n",
    "y_avg = df_avg.loan_status\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_avg_train, y_avg_train)\n",
    "print('RANDOM FOREST')\n",
    "scoring(rf, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "score:  0.9299980585674356\n",
      "balanced_accuracy_score:  0.8552458666304774\n",
      "[[108725  40952]\n",
      " [ 11691 590654]]\n",
      "F1 score:  0.9573378521513415\n",
      "precision_score:  0.9351621105562645\n",
      "average_precision_score:  0.927363761608714\n",
      "recall_score:  0.9805908573989989\n",
      "roc:  0.9353107874097656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_avg = df_avg.drop(['loan_status','grade'], axis=1)\n",
    "y_avg = df_avg.loan_status\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(class_weight ='balanced')\n",
    "\n",
    "rf.fit(X_avg_train, y_avg_train)\n",
    "print('RANDOM FOREST')\n",
    "scoring(rf, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest vasts outperforms logistic regression. We will try to combine classifiers in an attempt to improve our scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "score:  0.9285353354024217\n",
      "balanced_accuracy_score:  0.8610999091643115\n",
      "[[111019  38658]\n",
      " [ 15085 587260]]\n",
      "F1 score:  0.9562447130622677\n",
      "precision_score:  0.9382379161487607\n",
      "average_precision_score:  0.9303329430412478\n",
      "recall_score:  0.9749562128016336\n",
      "roc:  0.9375612930648483\n"
     ]
    }
   ],
   "source": [
    "#with logit_predict_proba feature\n",
    "\n",
    "X_avg_pred = pd.DataFrame(logit.predict_proba(X_avg)[:,1],columns =['logit_predict_proba'])\n",
    "X_avg_ = pd.concat([X_avg,X_avg_pred],axis=1)\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg_, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_avg_train,y_avg_train)\n",
    "print('RANDOM FOREST')\n",
    "scoring(rf, X_avg_test, y_avg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "score:  0.9283465111393018\n",
      "balanced_accuracy_score:  0.8618706337754759\n",
      "[[111384  38293]\n",
      " [ 15592 586753]]\n",
      "F1 score:  0.95609793456201\n",
      "precision_score:  0.9387357090518138\n",
      "average_precision_score:  0.9307211276378096\n",
      "recall_score:  0.9741145024861168\n",
      "roc:  0.937881932018431\n"
     ]
    }
   ],
   "source": [
    "#with gbm_predict_proba feature\n",
    "\n",
    "X_avg_pred = pd.DataFrame(gbm.predict_proba(X_avg)[:,1],columns =['gbm_predict_proba'])\n",
    "X_avg_gbm = pd.concat([X_avg,X_avg_pred],axis=1)\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg_gbm, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_avg_train,y_avg_train)\n",
    "print('RANDOM FOREST')\n",
    "scoring(rf, X_avg_test, y_avg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "score:  0.8074630795375667\n",
      "[[ 59929  89748]\n",
      " [ 55044 547301]]\n",
      "F1 score:  0.8831751646369113\n",
      "precision_score:  0.859119157239082\n",
      "recall_score:  0.9086171546206908\n",
      "roc:  0.7813935561514898\n"
     ]
    }
   ],
   "source": [
    "#just the predict_proba feature\n",
    "df_rf = pd.concat([X_avg_pred,y_avg],axis=1)\n",
    "\n",
    "X = pd.DataFrame(df_rf['logit_predict_proba'])\n",
    "y = pd.DataFrame(df_rf['loan_status'])\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_avg_train,y_avg_train)\n",
    "print('RANDOM FOREST')\n",
    "print('score: ', (rf.score(X_avg_test, y_avg_test)))\n",
    "    \n",
    "#print('balanced_accuracy_score: ', balanced_accuracy_score(y, clf.predict(x), sample_weight=x['loan_amnt']))\n",
    "\n",
    "print(confusion_matrix(y_avg_test, rf.predict(X_avg_test)))\n",
    "print('F1 score: ', f1_score(y_avg_test, rf.predict(X_avg_test)))\n",
    "print('precision_score: ',precision_score(y_avg_test, rf.predict(X_avg_test)))\n",
    "    \n",
    "#print('average_precision_score: ', average_precision_score(y, clf.predict(x), average='weighted', sample_weight=x['loan_amnt']))\n",
    "print('recall_score: ', recall_score(y_avg_test, rf.predict(X_avg_test)))\n",
    "    \n",
    "print('roc: ', roc_auc_score(y_avg_test, rf.predict_proba(X_avg_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some gains. Performs about the same, it maybe because there are too many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "score:  0.8379808037530817\n",
      "[[ 81829  67848]\n",
      " [ 53994 548351]]\n",
      "F1 score:  0.9000101760789927\n",
      "precision_score:  0.8898927132306285\n",
      "recall_score:  0.9103603416646606\n",
      "roc:  0.8312350288410958\n"
     ]
    }
   ],
   "source": [
    "#just the predict_proba feature\n",
    "df_rf = pd.concat([X_avg_pred,y_avg],axis=1)\n",
    "\n",
    "X = pd.DataFrame(df_rf['gbm_predict_proba'])\n",
    "y = pd.DataFrame(df_rf['loan_status'])\n",
    "\n",
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_avg_train,y_avg_train)\n",
    "print('RANDOM FOREST')\n",
    "print('score: ', (rf.score(X_avg_test, y_avg_test)))\n",
    "    \n",
    "#print('balanced_accuracy_score: ', balanced_accuracy_score(y, clf.predict(x), sample_weight=x['loan_amnt']))\n",
    "\n",
    "print(confusion_matrix(y_avg_test, rf.predict(X_avg_test)))\n",
    "print('F1 score: ', f1_score(y_avg_test, rf.predict(X_avg_test)))\n",
    "print('precision_score: ',precision_score(y_avg_test, rf.predict(X_avg_test)))\n",
    "    \n",
    "#print('average_precision_score: ', average_precision_score(y, clf.predict(x), average='weighted', sample_weight=x['loan_amnt']))\n",
    "print('recall_score: ', recall_score(y_avg_test, rf.predict(X_avg_test)))\n",
    "    \n",
    "print('roc: ', roc_auc_score(y_avg_test, rf.predict_proba(X_avg_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just the logit results as a feature resulted in a much lower score. There were much more false positives and false negatives compared to the massive feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.5913444021584475\n",
      "balanced_accuracy_score:  0.6140717696508232\n",
      "[[ 97559  52118]\n",
      " [255200 347145]]\n",
      "F1 score:  0.6931753739986102\n",
      "precision_score:  0.8694644883197291\n",
      "average_precision_score:  0.8282011180636957\n",
      "recall_score:  0.5763225394084786\n",
      "roc:  0.6630771823758567\n"
     ]
    }
   ],
   "source": [
    "X_avg_train, X_avg_test, y_avg_train, y_avg_test = train_test_split(\n",
    "X_avg, y_avg, test_size=0.3, random_state=42)\n",
    "\n",
    "logit_balanced = LogisticRegression(class_weight = 'balanced')\n",
    "\n",
    "logit_balanced.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_balanced, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009446532149326\n",
      "balanced_accuracy_score:  0.5002377383591609\n",
      "[[    56 149621]\n",
      " [    73 602272]]\n",
      "F1 score:  0.8894625612336975\n",
      "precision_score:  0.8010075901757298\n",
      "average_precision_score:  0.7856673290807463\n",
      "recall_score:  0.9998788069959906\n",
      "roc:  0.6443311934446472\n"
     ]
    }
   ],
   "source": [
    "#trying with nans filled with 0\n",
    "\n",
    "df_0 = df.fillna(0)\n",
    "\n",
    "X_0 = df_0.drop(['loan_status','grade'], axis=1)\n",
    "y_0 = df_0.loan_status\n",
    "\n",
    "X_0_train, X_0_test, y_0_train, y_0_test = train_test_split(\n",
    "X_0, y_0, test_size=0.3, random_state=42)\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_0_train, y_0_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit, X_0_test, y_0_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did not even matter, will try normalizing then hyper tuning 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8008635385666909\n",
      "balanced_accuracy_score:  0.5006189990261432\n",
      "[[   152 149525]\n",
      " [   230 602115]]\n",
      "F1 score:  0.8893968544703228\n",
      "precision_score:  0.8010683305837901\n",
      "average_precision_score:  0.7857958153749027\n",
      "recall_score:  0.9996181590284637\n",
      "roc:  0.6554825379834309\n"
     ]
    }
   ],
   "source": [
    "logit_c_0001 = LogisticRegression(C=.0001)\n",
    "\n",
    "logit_c_0001.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_0001, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009300259832824\n",
      "balanced_accuracy_score:  0.5004424141715003\n",
      "[[   103 149574]\n",
      " [   131 602214]]\n",
      "F1 score:  0.8894458668387817\n",
      "precision_score:  0.8010423151207521\n",
      "average_precision_score:  0.7857363003694248\n",
      "recall_score:  0.9997825166640381\n",
      "roc:  0.6514327242621893\n"
     ]
    }
   ],
   "source": [
    "logit_c_01 = LogisticRegression(C=.01)\n",
    "\n",
    "logit_c_01.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_01, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.800956620949919\n",
      "balanced_accuracy_score:  0.5002725321329511\n",
      "[[    60 149617]\n",
      " [    68 602277]]\n",
      "F1 score:  0.8894692886558428\n",
      "precision_score:  0.8010131747294167\n",
      "average_precision_score:  0.7856790529684031\n",
      "recall_score:  0.9998871078866762\n",
      "roc:  0.6449016175844058\n"
     ]
    }
   ],
   "source": [
    "logit_c_1 = LogisticRegression(C=.1)\n",
    "\n",
    "logit_c_1.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_1, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009419937182689\n",
      "balanced_accuracy_score:  0.5002239402258125\n",
      "[[    57 149620]\n",
      " [    76 602269]]\n",
      "F1 score:  0.8894607578896999\n",
      "precision_score:  0.8010078615327528\n",
      "average_precision_score:  0.7856626798467449\n",
      "recall_score:  0.9998738264615793\n",
      "roc:  0.640807180050564\n"
     ]
    }
   ],
   "source": [
    "logit_c_10 = LogisticRegression(C=10)\n",
    "\n",
    "logit_c_10.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_10, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009326854799461\n",
      "balanced_accuracy_score:  0.5002524657712254\n",
      "[[    64 149613]\n",
      " [    90 602255]]\n",
      "F1 score:  0.8894538746858877\n",
      "precision_score:  0.8010116137407098\n",
      "average_precision_score:  0.7856722914932446\n",
      "recall_score:  0.9998505839676597\n",
      "roc:  0.6424014797915372\n"
     ]
    }
   ],
   "source": [
    "logit_c_100 = LogisticRegression(C=100)\n",
    "\n",
    "logit_c_100.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_100, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009180582482959\n",
      "balanced_accuracy_score:  0.500493372619013\n",
      "[[   112 149565]\n",
      " [   149 602196]]\n",
      "F1 score:  0.8894370160090865\n",
      "precision_score:  0.801047141312199\n",
      "average_precision_score:  0.7857534741417198\n",
      "recall_score:  0.99975263345757\n",
      "roc:  0.65190125034441\n"
     ]
    }
   ],
   "source": [
    "logit_c_1000 = LogisticRegression(C=1000)\n",
    "\n",
    "logit_c_1000.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_1000, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "score:  0.8009300259832824\n",
      "balanced_accuracy_score:  0.5003103162678659\n",
      "[[    74 149603]\n",
      " [   102 602243]]\n",
      "F1 score:  0.8894506018722618\n",
      "precision_score:  0.8010190916756889\n",
      "average_precision_score:  0.7856917848676329\n",
      "recall_score:  0.9998306618300143\n",
      "roc:  0.6493744955895291\n"
     ]
    }
   ],
   "source": [
    "logit_c_10000 = LogisticRegression(C=10000)\n",
    "\n",
    "logit_c_10000.fit(X_avg_train, y_avg_train)\n",
    "print('LOGISTIC REGRESSION')\n",
    "scoring(logit_c_10000, X_avg_test, y_avg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with varying C values has yielded no significant improvements for their respective scores. If there are any winners it would be c = 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "parameters = {'loss' : ['deviance', 'exponential']}\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "gb_cv = GridSearchCV(gbm, parameters, cv=5)\n",
    "\n",
    "gb_cv.fit(X_avg,y_avg)\n",
    "\n",
    "gb_cv.best_score_\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes and hyper-tuning. POOR CLASSIFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#var_smoothing : float, optional (default=1e-9)\n",
    "\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "X = df_i.drop(['loan_status'], axis=1)\n",
    "y = df_i.loan_status\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gaussian_nb.fit(X_train, y_train)\n",
    "\n",
    "scoring(gaussian_nb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#var_smoothing : float, optional (default=1e-9)\n",
    "\n",
    "gaussian_nb = GaussianNB(var_smoothing = 10000.0)\n",
    "\n",
    "X = df_i.drop(['loan_status'], axis=1)\n",
    "y = df_i.loan_status\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gaussian_nb.fit(X_train, y_train)\n",
    "\n",
    "scoring(gaussian_nb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#alpha : float, optional (default=1.0)\n",
    "bernoulli_nb = BernoulliNB()\n",
    "\n",
    "X = df_i.drop(['loan_status'], axis=1)\n",
    "y = df_i.loan_status\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "bernoulli_nb.fit(X_train, y_train)\n",
    "\n",
    "scoring(bernoulli_nb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'var_smoothing':np.logspace(np.log10(.000000001),np.log10(10000),5)}\n",
    "\n",
    "grid_gaussian_nb = GridSearchCV(gaussian_nb,parameters, cv=5)\n",
    "xx = df_i.drop(columns=['loan_status'])\n",
    "yy = pd.DataFrame(df_i['loan_status'])\n",
    "grid_gaussian_nb.fit(xx,yy)\n",
    "\n",
    "grid_gaussian_nb.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha':np.logspace(np.log10(.000000001),np.log10(10000),5)}\n",
    "\n",
    "grid_bernoulli_nb = GridSearchCV(bernoulli_nb,parameters, cv=5)\n",
    "xx = df_i.drop(columns=['loan_status'])\n",
    "yy = pd.DataFrame(df_i['loan_status'])\n",
    "grid_bernoulli_nb.fit(xx,yy)\n",
    "\n",
    "grid_bernoulli_nb.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':np.logspace(np.log10(.0001),np.log10(10000),5)}\n",
    "\n",
    "logit_cv = GridSearchCV(logit, parameters, cv=5)\n",
    "\n",
    "logit_cv.fit(X_avg,y_avg)\n",
    "\n",
    "logit_cv.best_score_'''\n",
    "#took too long to run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = LogisticRegressionCV(cv=5,solver='liblinear', Cs=np.logspace(np.log10(.0001),np.log10(10000),5),scoring='roc_auc')\n",
    "\n",
    "clf.fit(X_avg,y_avg)\n",
    "print(clf.scores_)\n",
    "\n",
    "clf.fit(X_0,y_0)\n",
    "print(clf.scores_)'''\n",
    "#takes forever to run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
